---
---

@string{aps = {American Physical Society,}}

@inproceedings{10.1145/3703323.3703333,
  author    = {Govind, Ishwar and Thomas, Jerry and Lakshminarayanan, Chandrashekar},
  title     = {Deployability of Deep Reinforcement Learning in Portfolio Management},
  year      = {2025},
  isbn      = {9798400711244},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3703323.3703333},
  doi       = {10.1145/3703323.3703333},
  abstract  = {Portfolio management is a classical problem that has been studied in the financial literature in a wide variety of settings. In recent years, deep reinforcement learning (DRL) agents have been proposed as a potential solution for portfolio management. In this paper, we look at two fundamental challenges. (i) There is no common baseline to compare the various DRL agents, and (ii) there is no straightforward way to check if the DRL agents are indeed learning the near-optimal policy. To address these two challenges, we study the performance of DRL agents of varying complexity on the synthetic market based on a simplified version of the Baba-Engle-Kraft-Kroner (BEKK) model. We empirically demonstrate the following: (i) not all DRL agents perform well in the synthetic market; (ii) DRL agents that perform well in the synthetic market learn policies that align with the optimal policy obtained from a maximum Sharpe Ratio portfolio.},
  booktitle = {Proceedings of the 8th International Conference on Data Science and Management of Data (12th ACM IKDD CODS and 30th COMAD)},
  pages     = {61â€“65},
  numpages  = {5},
  location  = {
               },
  selected  = {true},
  series    = {CODS-COMAD '24},
  preview = {stock_market.gif}
}


