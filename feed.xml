<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ishwargov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ishwargov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-24T20:08:32+00:00</updated><id>https://ishwargov.github.io/feed.xml</id><title type="html">blank</title><subtitle>Ishwar</subtitle><entry><title type="html">Notes on RNN and LSTM for reference</title><link href="https://ishwargov.github.io/blog/2025/notes-on-rnn/" rel="alternate" type="text/html" title="Notes on RNN and LSTM for reference"/><published>2025-07-23T21:01:00+00:00</published><updated>2025-07-23T21:01:00+00:00</updated><id>https://ishwargov.github.io/blog/2025/notes-on-rnn</id><content type="html" xml:base="https://ishwargov.github.io/blog/2025/notes-on-rnn/"><![CDATA[<h2 id="differential-equation-derivation-of-rnn">Differential Equation derivation of RNN</h2> <p>Let $s(t)$ be the d dimensional state signal vector and $h(s(t),x(t))$ be one of the canonical forms of a d-dimensional $f(t)$ where: \(\frac{ d s(t) }{ dt } = f(t) = h(s(t),x(t)) +\phi\) where one of its special case is based on the “additive model” in brain dynamics research literature given by $f(t) = a(t)+b(t)+c(t)$</p> <p>where: \(\frac{ds}{dt} = \sum^{K_s-1}_{k=0} a_k(s(t-\tau_s(k))) + \sum^{K_r-1}_{k=0} b_k(r(t-\tau_r(k))) + \sum^{K_x-1}_{k=0} c_k(x(t-\tau_x(k))) + \phi\) \(r(t-\tau_r(k)) = G(s(t-\tau_r(k)))\) Here $G(z)$ is considered a element-wise non-linear saturating “warping” ( activation ) function.</p> <p>The above equation is considered a nonlinear ordinary delay differential equation DDE with discrete delays. Delay is used to match the appropriate nature of the process.</p> <p><code class="language-plaintext highlighter-rouge">The rationale behind choosing a form of the hyperbolic tangent as the warping function is due to it being monotonic and negative-symmetric with quasi-linear region, whose slope can be regulated. Bipolarly Saturating , </code> ( properties for an activation function ? )</p> <ul> <li>a - “analog” state singal ( controls the stability of the system )</li> <li>b - long term behaviour from signals</li> <li>c - initial input signal</li> <li>warping function for extracting signal</li> <li>time delay for the “memory” aspects of the system</li> </ul> <p>Now assuming that the 3 functions associated with (a,b,c) are linear. (Continous Hopfield Network) Earlier studies linked the nonlinear dynamical systems formalized previously with $K_s=K_r=K_x=1$ and all $\tau’s$ to zero to a type of neural network. Finally the equation, becomes: \(\frac{ds}{dt} = A(s(t)) + B(r(t-\tau)) + C(x(t)) + \phi\)</p> <p>Applying <a href="https://math.libretexts.org/Bookshelves/Differential_Equations/Numerically_Solving_Ordinary_Differential_Equations_(Brorson)/01%3A_Chapters/1.02%3A_Forward_Euler_method">Euler discretization rule</a> to the previous equation: ( for n time steps and $\tau$ as a single time step - $\Delta T$)</p> \[\frac{s(n \Delta T+ \Delta T ) - s(n\Delta T)}{\Delta T} = A(s(n \Delta T+ \Delta T )) + B(r(n \Delta T )) + C(x(n \Delta T+ \Delta T )) + \phi\] <p>The reason for setting $\tau$ to a single time step is to store the value of the readout signal into the memory for the next step. We can keep overwriting it for the next steps so on.</p>]]></content><author><name></name></author><category term="formatting"/><category term="code"/><category term="rnn"/><category term="lstm"/><summary type="html"><![CDATA[Notes on paper - Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network]]></summary></entry><entry><title type="html">InCTF 2020 : Find Me If You Can, Writeup</title><link href="https://ishwargov.github.io/blog/2020/inctf-2020-find-me-if-you-can-writeup/" rel="alternate" type="text/html" title="InCTF 2020 : Find Me If You Can, Writeup"/><published>2020-08-04T15:22:35+00:00</published><updated>2020-08-04T15:22:35+00:00</updated><id>https://ishwargov.github.io/blog/2020/inctf-2020-find-me-if-you-can-writeup</id><content type="html" xml:base="https://ishwargov.github.io/blog/2020/inctf-2020-find-me-if-you-can-writeup/"><![CDATA[<h3>InCTF 2020 : Find Me If You Can, Writeup</h3> <p>Writeup on the CTF problem based on Machine Learning.</p> <h4>Team <a href="https://ctftime.org/team/119879">S1lySUUz</a></h4> <p>We are provided an address and a port. After running through netcat we get a blob with an instruction given</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*7OgTfZCc7_vBae25-h8d7g.png"/><figcaption>data we get through netcat</figcaption></figure> <p>We are given a large blob of data (256kb) encoded in <strong>base64 </strong>. After decoding this we get a file with a header of <strong>78 9c</strong> (<strong>Zlib Compressed data</strong>). After decompressing it I am given a JPEG header file which has a size of 560x560 pixels.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/560/1*lNJ7sACNKwAPbkA_KNzxsA.jpeg"/></figure> <p>Looks like they made a 20x20 Image table out of Digits MNIST Dataset. <strong>MNIST</strong> (“Modified National Institute of Standards and Technology”) is the de facto “hello world” <strong>dataset</strong> of computer vision. Now the question is to solve this captcha by using a trained <strong>Digits MNIST model</strong> and send the odd one out’s coordinates. 1 image is wrong out of the 400 28x28 pixel images.</p> <p>For this problem I used a model that I trained using 42000 images in Keras, long back for the Digits MNIST.</p> <h3>CNN Model:</h3> <pre>model = Sequential([<br />    <br />    <br />    Conv2D(filters = 64, kernel_size = (3,3),padding = &#39;Same&#39;, activation =&#39;relu&#39;, input_shape = (28,28,1)),<br />    BatchNormalization(),</pre> <pre>Conv2D(filters = 64, kernel_size = (5,5),padding = &#39;Same&#39;, activation =&#39;relu&#39;),<br />    BatchNormalization(),</pre> <pre>MaxPooling2D(pool_size=(2,2)),<br />    Dropout(0.25),<br />    <br />    Conv2D(filters = 64, kernel_size = (3,3),padding = &#39;Same&#39;, activation =&#39;relu&#39;),<br />    BatchNormalization(),</pre> <pre>Conv2D(filters = 64, kernel_size = (3,3),padding = &#39;Same&#39;, activation =&#39;relu&#39;),<br />    BatchNormalization(),<br />    MaxPooling2D(pool_size=(2,2), strides=(2,2)),<br />    Dropout(0.25),</pre> <pre>Conv2D(filters = 64, kernel_size = (3,3), padding = &#39;Same&#39;,  activation =&#39;relu&#39;),<br />    BatchNormalization(),<br />    Dropout(0.25),</pre> <pre>Flatten(),<br />    Dense(256, activation = &quot;relu&quot;),<br />    BatchNormalization(),<br />    Dropout(0.25),</pre> <pre>Dense(10, activation = &quot;softmax&quot;)<br />])</pre> <pre>model.compile(optimizer=&#39;adam&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])</pre> <pre>hst = model.fit(train_images,train_labels,epochs=50,validation_data = (test_images,test_labels),batch_size=32)</pre> <p>The CNN model I trained had an <strong>accuracy 99.86</strong>. As they are giving us 3 tries of coordinates I thought of making use of the <strong>softmax function</strong> I get after each image prediction. So I made a <strong>2D 20x20 array</strong> which contains the values of the softmax value at the actual digit’s index. Then send the coordinates of the ones with the least 3 values.</p> <p>I used the <strong>pwntools</strong> library in python for the netcat data transcation.</p> <h3>Final Code:</h3> <pre>from pwn import *<br />import base64<br />from PIL import Image<br />import zlib<br />import numpy as np<br />import tensorflow as tf<br />from tensorflow import keras<br />import matplotlib.pyplot as plt<br />from statistics import mode</pre> <pre>model = keras.models.load_model(&#39;cnn_mnist_model.h5&#39;)#loading the pretrained model</pre> <pre>conn = remote(&#39;34.x.x.x&#39;,7777)<br />data = conn.recv()</pre> <p>Then Solve the Captcha question on a loop until the flag arrives.</p> <pre>while True:  <br />    conn.recvuntil(&#39;b\&#39;&#39;, drop=True)<br />    image_data = conn.recvline()<br />    image_data = image_data[:-2]<br />    image_data = image_data.decode(&#39;utf-8&#39;)<br />    image_file = zlib.decompress(base64.b64decode(image_data))<br />    f = open(&#39;image.jpeg&#39;,&#39;wb&#39;)<br />    f.write(image_file)<br />    f.close()<br />    image = Image.open(&#39;image.jpeg&#39;)<br />    imarray = np.asarray(image.convert(&#39;L&#39;)).reshape(560,560)<br />    imarray = imarray/255.0<br />    digit = mode([int(np.argmax(model.predict(imarray[:28,:28].reshape(1,28,28,1)),axis=1)),<br />                 int(np.argmax(model.predict(imarray[28:2*28,:28].reshape(1,28,28,1)),axis=1)),<br />                 int(np.argmax(model.predict(imarray[2*28:3*28,:28].reshape(1,28,28,1)),axis=1))])<br />    print(digit)<br />    x1=0<br />    y1=0<br />    x2=0<br />    y2=0<br />    x3=0<br />    y3=0<br />    ans = np.ones(shape=(20,20,1))<br />    for i in range(20):<br />        for j in range(20):<br />            imagdat = imarray[i*28:(i+1)*28,j*28:(j+1)*28]<br />            imagdat = imagdat.reshape(1,28,28,1)<br />            #preds = int(np.argmax(model.predict(imagdat),axis=1))<br />            ans[i,j,0]=model.predict(imagdat)[0,digit]<br />    y1 = np.argmin(ans)%20<br />    x1 = np.argmin(ans)//20<br />    ans[x1,y1,0]=1<br />    y2 = np.argmin(ans)%20<br />    x2 = np.argmin(ans)//20<br />    ans[x2,y2,0]=1<br />    y3 = np.argmin(ans)%20<br />    x3 = np.argmin(ans)//20<br />    ans[x3,y3,0]=1<br />    sendmsg = str((x1,y1,x2,y2,x3,y3))<br />    print(sendmsg)<br />    conn.sendline(sendmsg)<br />    flag = conn.recvline()<br />    if flag != b&#39;Correct! onto the next one then\n&#39;:<br />        print(flag)<br />        break</pre> <p>After 100 captchas and voila! the flag.</p> <pre>inctf{1_D4Y_R0b0t5_w1ll_rul3_th3_w0rld_4_5UR3!!}</pre> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=2120213feba1" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>